{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Logistic Regression, LDA, QDA, and KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6.1 The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "Year                                                                  \n",
       "2001-01-01  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "2001-01-01  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "2001-01-01  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "2001-01-01 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "2001-01-01  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('./datasets/Smarket.csv',usecols=range(1,10), index_col=0, parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume', 'Today', 'Direction'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250, 8)\n"
     ]
    }
   ],
   "source": [
    "# Shape\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Lag1         Lag2         Lag3         Lag4        Lag5  \\\n",
      "count  1250.000000  1250.000000  1250.000000  1250.000000  1250.00000   \n",
      "mean      0.003834     0.003919     0.001716     0.001636     0.00561   \n",
      "std       1.136299     1.136280     1.138703     1.138774     1.14755   \n",
      "min      -4.922000    -4.922000    -4.922000    -4.922000    -4.92200   \n",
      "25%      -0.639500    -0.639500    -0.640000    -0.640000    -0.64000   \n",
      "50%       0.039000     0.039000     0.038500     0.038500     0.03850   \n",
      "75%       0.596750     0.596750     0.596750     0.596750     0.59700   \n",
      "max       5.733000     5.733000     5.733000     5.733000     5.73300   \n",
      "\n",
      "            Volume        Today  \n",
      "count  1250.000000  1250.000000  \n",
      "mean      1.478305     0.003138  \n",
      "std       0.360357     1.136334  \n",
      "min       0.356070    -4.922000  \n",
      "25%       1.257400    -0.639500  \n",
      "50%       1.422950     0.038500  \n",
      "75%       1.641675     0.596750  \n",
      "max       3.152470     5.733000  \n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1250 entries, 2001-01-01 to 2005-01-01\n",
      "Data columns (total 8 columns):\n",
      "Lag1         1250 non-null float64\n",
      "Lag2         1250 non-null float64\n",
      "Lag3         1250 non-null float64\n",
      "Lag4         1250 non-null float64\n",
      "Lag5         1250 non-null float64\n",
      "Volume       1250 non-null float64\n",
      "Today        1250 non-null float64\n",
      "Direction    1250 non-null object\n",
      "dtypes: float64(7), object(1)\n",
      "memory usage: 87.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Info\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Lag1      Lag2      Lag3      Lag4      Lag5    Volume     Today\n",
      "Lag1    1.000000 -0.026294 -0.010803 -0.002986 -0.005675  0.040910 -0.026155\n",
      "Lag2   -0.026294  1.000000 -0.025897 -0.010854 -0.003558 -0.043383 -0.010250\n",
      "Lag3   -0.010803 -0.025897  1.000000 -0.024051 -0.018808 -0.041824 -0.002448\n",
      "Lag4   -0.002986 -0.010854 -0.024051  1.000000 -0.027084 -0.048414 -0.006900\n",
      "Lag5   -0.005675 -0.003558 -0.018808 -0.027084  1.000000 -0.022002 -0.034860\n",
      "Volume  0.040910 -0.043383 -0.041824 -0.048414 -0.022002  1.000000  0.014592\n",
      "Today  -0.026155 -0.010250 -0.002448 -0.006900 -0.034860  0.014592  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Correlation\n",
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit a logistic regression in order to predict **Direction** using **Lag1** through **Lag5** and **Volume**. We use the *glm()* function from statsmodels. It takes as an input a formula, a dataset, and a family. In our case, we use the Binomial family to perform the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'Direction ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.formula.glm(formula,df,family = sm.families.Binomial())\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Generalized Linear Model Regression Results                           \n",
      "================================================================================================\n",
      "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1250\n",
      "Model:                                              GLM   Df Residuals:                     1243\n",
      "Model Family:                                  Binomial   Df Model:                            6\n",
      "Link Function:                                    logit   Scale:                             1.0\n",
      "Method:                                            IRLS   Log-Likelihood:                -863.79\n",
      "Date:                                  Wed, 11 Jul 2018   Deviance:                       1727.6\n",
      "Time:                                          21:00:12   Pearson chi2:                 1.25e+03\n",
      "No. Iterations:                                       4                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1260      0.241      0.523      0.601      -0.346       0.598\n",
      "Lag1           0.0731      0.050      1.457      0.145      -0.025       0.171\n",
      "Lag2           0.0423      0.050      0.845      0.398      -0.056       0.140\n",
      "Lag3          -0.0111      0.050     -0.222      0.824      -0.109       0.087\n",
      "Lag4          -0.0094      0.050     -0.187      0.851      -0.107       0.089\n",
      "Lag5          -0.0103      0.050     -0.208      0.835      -0.107       0.087\n",
      "Volume        -0.1354      0.158     -0.855      0.392      -0.446       0.175\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smallest p-value is associated with lag1. However, at a value of 0.145, there is no clear evidence of a real association between **Lag1** and **Direction**. We now list the coefficient of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeffieients\n",
      "Intercept    0.126000\n",
      "Lag1         0.073074\n",
      "Lag2         0.042301\n",
      "Lag3        -0.011085\n",
      "Lag4        -0.009359\n",
      "Lag5        -0.010313\n",
      "Volume      -0.135441\n",
      "dtype: float64\n",
      "p-Values\n",
      "Intercept    0.600700\n",
      "Lag1         0.145232\n",
      "Lag2         0.398352\n",
      "Lag3         0.824334\n",
      "Lag4         0.851445\n",
      "Lag5         0.834998\n",
      "Volume       0.392404\n",
      "dtype: float64\n",
      "Dependent variables\n",
      "['Direction[Down]', 'Direction[Up]']\n"
     ]
    }
   ],
   "source": [
    "print(\"Coeffieients\")\n",
    "print(result.params)\n",
    "print\n",
    "print(\"p-Values\")\n",
    "print(result.pvalues)\n",
    "print\n",
    "print(\"Dependent variables\")\n",
    "print(result.model.endog_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ${\\tt predict()}$ function can be used to predict the probability that the market will go down, given values of the predictors. If no data set is supplied to the ${\\tt predict()}$ function, then the probabilities are computed for the training data that was used to fit the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49291587 0.51853212 0.51886117 0.48477764 0.48921884 0.49304354\n",
      " 0.50734913 0.49077084 0.48238647 0.51116222]\n"
     ]
    }
   ],
   "source": [
    "predictions = result.predict()\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign predictions\n",
    "glm_pred = ['Up' if x<0.5 else 'Down' for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[145, 457],\n",
       "       [141, 507]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "confusion_matrix(df.Direction,glm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative =  145\n",
      "False Positive =  457\n",
      "False Negative =  141\n",
      "True Positive =  507\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(df.Direction,glm_pred).ravel()\n",
    "print(\"True Negative = \", tn)\n",
    "print(\"False Positive = \", fp)\n",
    "print(\"False Negative = \", fn)\n",
    "print(\"True Positive = \", tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagonal elements of the confusion matrix indicate correct predictions, while the off-diagonals represent incorrect predictions. Hence our model correctly predicted that the market would go up on 507 days and that it would go down on 145 days, for a total of 507 + 145 = 652 correct predictions. In this case, logistic regression correctly predicted the movement of the market 52.2% of the time. this is confirmed by checking the output of the  𝚌𝚕𝚊𝚜𝚜𝚒𝚏𝚒𝚌𝚊𝚝𝚒𝚘𝚗⎯𝚛𝚎𝚙𝚘𝚛𝚝()classification_report()  function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down       0.51      0.24      0.33       602\n",
      "         Up       0.53      0.78      0.63       648\n",
      "\n",
      "avg / total       0.52      0.52      0.48      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(df.Direction,glm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, it appears that the logistic regression model is working\n",
    "a little better than random guessing. But remember, this result is misleading\n",
    "because we trained and tested the model on the same set of 1,250 observations.\n",
    "In other words, 100− 52.2 = 47.8% is the **training error rate**. As we\n",
    "have seen previously, the training error rate is often overly optimistic — it\n",
    "tends to underestimate the _test_ error rate. \n",
    "\n",
    "In order to better assess the accuracy\n",
    "of the logistic regression model in this setting, we can fit the model\n",
    "using part of the data, and then examine how well it predicts the held out\n",
    "data. This will yield a more realistic error rate, in the sense that in practice\n",
    "we will be interested in our model’s performance not on the data that\n",
    "we used to fit the model, but rather on days in the future for which the\n",
    "market’s movements are unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We creaate a vector containing the observations from 2001 to 2004 and make predictions on the 2005 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[:'2004'][:]\n",
    "y_train = df[:'2004']['Direction']\n",
    "\n",
    "X_test = df['2005':][:]\n",
    "y_test = df['2005':]['Direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 8)\n"
     ]
    }
   ],
   "source": [
    "# Shape of test set\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create and fit the logistic regression\n",
    "model = sm.formula.glm(formula=formula, data=X_train, family=sm.families.Binomial())\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "2005-01-01    0.471780\n",
      "2005-01-01    0.484331\n",
      "2005-01-01    0.477348\n",
      "2005-01-01    0.486146\n",
      "2005-01-01    0.501666\n",
      "2005-01-01    0.498909\n",
      "2005-01-01    0.497230\n",
      "2005-01-01    0.490432\n",
      "2005-01-01    0.495989\n",
      "2005-01-01    0.489359\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = result.predict(X_test)\n",
    "print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign predictions\n",
    "glm_pred = ['Up' if x<0.5 else 'Down' for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77, 34],\n",
       "       [97, 44]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "confusion_matrix(y_test,glm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative =  77\n",
      "False Positive =  34\n",
      "False Negative =  97\n",
      "True Positive =  44\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test,glm_pred).ravel()\n",
    "print(\"True Negative = \", tn)\n",
    "print(\"False Positive = \", fp)\n",
    "print(\"False Negative = \", fn)\n",
    "print(\"True Positive = \", tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are rather disappointing: the test error rate (1 -  𝚛𝚎𝚌𝚊𝚕𝚕recall ) is 52%, which is worse than random guessing! Of course, this result is not all that surprising, given that one would not generally expect to be able to use previous days’ returns to predict future market performance. (After all, if it were possible to do so, then the authors of this book [along with your professor] would probably be out striking it rich rather than teaching statistics.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall that the logistic regression model had very underwhelming p-values associated with all of the predictors, and that the smallest p-value, though not very small, corresponded to  𝙻𝚊𝚐𝟷Lag1 . Perhaps by removing the variables that appear not to be helpful in predicting  𝙳𝚒𝚛𝚎𝚌𝚝𝚒𝚘𝚗Direction , we can obtain a more effective model. After all, using predictors that have no relationship with the response tends to cause a deterioration in the test error rate (since such predictors cause an increase in variance without a corresponding decrease in bias), and so removing such predictors may in turn yield an improvement.\n",
    "\n",
    "In the space below, refit a logistic regression using just  𝙻𝚊𝚐𝟷  and  𝙻𝚊𝚐𝟸 , which seemed to have the highest predictive power in the original logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'Direction ~ Lag1+Lag2+Volume'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.formula.glm(formula,df,family = sm.families.Binomial())\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Generalized Linear Model Regression Results                           \n",
      "================================================================================================\n",
      "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1250\n",
      "Model:                                              GLM   Df Residuals:                     1246\n",
      "Model Family:                                  Binomial   Df Model:                            3\n",
      "Link Function:                                    logit   Scale:                             1.0\n",
      "Method:                                            IRLS   Log-Likelihood:                -863.85\n",
      "Date:                                  Wed, 11 Jul 2018   Deviance:                       1727.7\n",
      "Time:                                          21:00:12   Pearson chi2:                 1.25e+03\n",
      "No. Iterations:                                       4                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1206      0.240      0.502      0.616      -0.350       0.591\n",
      "Lag1           0.0733      0.050      1.460      0.144      -0.025       0.172\n",
      "Lag2           0.0428      0.050      0.855      0.393      -0.055       0.141\n",
      "Volume        -0.1318      0.158     -0.835      0.404      -0.441       0.178\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = result.predict(X_test)\n",
    "\n",
    "# Assign predictions\n",
    "glm_pred = ['Up' if x<0.5 else 'Down' for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4, 107],\n",
       "       [  1, 140]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "confusion_matrix(y_test,glm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative =  4\n",
      "False Positive =  107\n",
      "False Negative =  1\n",
      "True Positive =  140\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test,glm_pred).ravel()\n",
    "print(\"True Negative = \", tn)\n",
    "print(\"False Positive = \", fp)\n",
    "print(\"False Negative = \", fn)\n",
    "print(\"True Positive = \", tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.3 Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "Year                                                                  \n",
       "2001-01-01  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "2001-01-01  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "2001-01-01  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "2001-01-01 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "2001-01-01  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('./datasets/Smarket.csv',usecols=range(1,10), index_col=0, parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model using only observations before 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "X_train = df[:'2004'][['Lag1','Lag2']]\n",
    "y_train = df[:'2004']['Direction']\n",
    "\n",
    "# Test data\n",
    "X_test = df['2005':][['Lag1','Lag2']]\n",
    "y_test = df['2005':]['Direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit model\n",
    "lda = LDA()\n",
    "lda.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49198397 0.50801603]\n"
     ]
    }
   ],
   "source": [
    "# Prior probabilities of groups:\n",
    "print(lda.priors_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LDA output indicates prior probabilities of ${\\hat{\\pi}}_1 = 0.492$ and ${\\hat{\\pi}}_2 = 0.508$; in other words,\n",
    "49.2% of the training observations correspond to days during which the market went down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04279022  0.03389409]\n",
      " [-0.03954635 -0.03132544]]\n"
     ]
    }
   ],
   "source": [
    "# Group means\n",
    "print(lda.means_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above provides the group means; these are the average of each predictor within each class, and are used by LDA as estimates\n",
    "of $\\mu_k$. These suggest that there is a tendency for the previous 2 days’ returns to be negative on days when the market increases, and a tendency\n",
    "for the previous days’ returns to be positive on days when the market declines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05544078 -0.0443452 ]]\n"
     ]
    }
   ],
   "source": [
    "# Coefficients of linear discriminants:\n",
    "print(lda.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *coefficients of linear discriminatns* output provides the linear combination of ${\\tt Lag1}$ and ${\\tt Lag2}$ that are used to form the LDA decision rule. In other words, these are the multipliers of teh elements of X=x. If -0.05544078*${\\tt Lag1}$-0.0443452*${\\tt Lag2}$ is large, then the LDA classifier will predict a market increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on the 2005 data\n",
    "y_pred = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['Down', 'Up'], dtype='<U4'), array([ 70, 182]))\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "print(np.unique(y_pred,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 35  76]\n",
      " [ 35 106]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down       0.50      0.32      0.39       111\n",
      "         Up       0.58      0.75      0.66       141\n",
      "\n",
      "avg / total       0.55      0.56      0.54       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "# Manually recreate the prediction\n",
    "y_pred_prob = lda.predict_proba(X_test)\n",
    "print(np.sum(y_pred_prob[:,1] <= 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.4 Quadratic Discriminant Analysis\n",
    "\n",
    "In this section, we will fit a QDA model to the stock market data prior to 2005 to make prediction on the 2005 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "               store_covariance=False, store_covariances=None, tol=0.0001)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit model\n",
    "qda = QDA()\n",
    "qda.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49198397 0.50801603]\n"
     ]
    }
   ],
   "source": [
    "# Prior probabilities of groups:\n",
    "print(lda.priors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04279022  0.03389409]\n",
      " [-0.03954635 -0.03132544]]\n"
     ]
    }
   ],
   "source": [
    "# Group means\n",
    "print(lda.means_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the prior probabilities and the means are identical to those of the LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction on the 2005 data\n",
    "y_pred = qda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30  81]\n",
      " [ 20 121]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down       0.60      0.27      0.37       111\n",
      "         Up       0.60      0.86      0.71       141\n",
      "\n",
      "avg / total       0.60      0.60      0.56       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QDA reaches a precision of 60% compare to the 55% obtained from the LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.5 K-Nearest Neighbors\n",
    "We will now perform KNN using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requiered library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "y_pred = knn.fit(X_train,y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 55]\n",
      " [63 86]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down       0.47      0.43      0.45       111\n",
      "         Up       0.58      0.61      0.59       141\n",
      "\n",
      "avg / total       0.53      0.53      0.53       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our precision is only 53%, so just a little better than a random classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c23184c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimize the number of clusters\n",
    "accuracy = []\n",
    "\n",
    "for k in range(2,50):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    y_pred = knn.fit(X_train,y_train).predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "   \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(2,50), accuracy, c=\"g\", alpha=0.5)\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6.6 An Application to Caravan Insurance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>...</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  \\\n",
       "0           1       33         1        3         2         8       0       5   \n",
       "1           2       37         1        2         2         8       1       4   \n",
       "2           3       37         1        2         2         8       0       4   \n",
       "3           4        9         1        3         3         3       2       3   \n",
       "4           5       40         1        4         2        10       1       4   \n",
       "\n",
       "   MGODOV  MGODGE    ...     APERSONG  AGEZONG  AWAOREG  ABRAND  AZEILPL  \\\n",
       "0       1       3    ...            0        0        0       1        0   \n",
       "1       1       4    ...            0        0        0       1        0   \n",
       "2       2       4    ...            0        0        0       1        0   \n",
       "3       2       4    ...            0        0        0       1        0   \n",
       "4       1       4    ...            0        0        0       1        0   \n",
       "\n",
       "   APLEZIER  AFIETS  AINBOED  ABYSTAND  Purchase  \n",
       "0         0       0        0         0        No  \n",
       "1         0       0        0         0        No  \n",
       "2         0       0        0         0        No  \n",
       "3         0       0        0         0        No  \n",
       "4         0       0        0         0        No  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('./datasets/Caravan.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'MOSTYPE', 'MAANTHUI', 'MGEMOMV', 'MGEMLEEF', 'MOSHOOFD',\n",
      "       'MGODRK', 'MGODPR', 'MGODOV', 'MGODGE', 'MRELGE', 'MRELSA', 'MRELOV',\n",
      "       'MFALLEEN', 'MFGEKIND', 'MFWEKIND', 'MOPLHOOG', 'MOPLMIDD', 'MOPLLAAG',\n",
      "       'MBERHOOG', 'MBERZELF', 'MBERBOER', 'MBERMIDD', 'MBERARBG', 'MBERARBO',\n",
      "       'MSKA', 'MSKB1', 'MSKB2', 'MSKC', 'MSKD', 'MHHUUR', 'MHKOOP', 'MAUT1',\n",
      "       'MAUT2', 'MAUT0', 'MZFONDS', 'MZPART', 'MINKM30', 'MINK3045',\n",
      "       'MINK4575', 'MINK7512', 'MINK123M', 'MINKGEM', 'MKOOPKLA', 'PWAPART',\n",
      "       'PWABEDR', 'PWALAND', 'PPERSAUT', 'PBESAUT', 'PMOTSCO', 'PVRAAUT',\n",
      "       'PAANHANG', 'PTRACTOR', 'PWERKT', 'PBROM', 'PLEVEN', 'PPERSONG',\n",
      "       'PGEZONG', 'PWAOREG', 'PBRAND', 'PZEILPL', 'PPLEZIER', 'PFIETS',\n",
      "       'PINBOED', 'PBYSTAND', 'AWAPART', 'AWABEDR', 'AWALAND', 'APERSAUT',\n",
      "       'ABESAUT', 'AMOTSCO', 'AVRAAUT', 'AAANHANG', 'ATRACTOR', 'AWERKT',\n",
      "       'ABROM', 'ALEVEN', 'APERSONG', 'AGEZONG', 'AWAOREG', 'ABRAND',\n",
      "       'AZEILPL', 'APLEZIER', 'AFIETS', 'AINBOED', 'ABYSTAND', 'Purchase'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5822, 87)\n"
     ]
    }
   ],
   "source": [
    "# Explore data\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 87 columns):\n",
      "Unnamed: 0    5822 non-null int64\n",
      "MOSTYPE       5822 non-null int64\n",
      "MAANTHUI      5822 non-null int64\n",
      "MGEMOMV       5822 non-null int64\n",
      "MGEMLEEF      5822 non-null int64\n",
      "MOSHOOFD      5822 non-null int64\n",
      "MGODRK        5822 non-null int64\n",
      "MGODPR        5822 non-null int64\n",
      "MGODOV        5822 non-null int64\n",
      "MGODGE        5822 non-null int64\n",
      "MRELGE        5822 non-null int64\n",
      "MRELSA        5822 non-null int64\n",
      "MRELOV        5822 non-null int64\n",
      "MFALLEEN      5822 non-null int64\n",
      "MFGEKIND      5822 non-null int64\n",
      "MFWEKIND      5822 non-null int64\n",
      "MOPLHOOG      5822 non-null int64\n",
      "MOPLMIDD      5822 non-null int64\n",
      "MOPLLAAG      5822 non-null int64\n",
      "MBERHOOG      5822 non-null int64\n",
      "MBERZELF      5822 non-null int64\n",
      "MBERBOER      5822 non-null int64\n",
      "MBERMIDD      5822 non-null int64\n",
      "MBERARBG      5822 non-null int64\n",
      "MBERARBO      5822 non-null int64\n",
      "MSKA          5822 non-null int64\n",
      "MSKB1         5822 non-null int64\n",
      "MSKB2         5822 non-null int64\n",
      "MSKC          5822 non-null int64\n",
      "MSKD          5822 non-null int64\n",
      "MHHUUR        5822 non-null int64\n",
      "MHKOOP        5822 non-null int64\n",
      "MAUT1         5822 non-null int64\n",
      "MAUT2         5822 non-null int64\n",
      "MAUT0         5822 non-null int64\n",
      "MZFONDS       5822 non-null int64\n",
      "MZPART        5822 non-null int64\n",
      "MINKM30       5822 non-null int64\n",
      "MINK3045      5822 non-null int64\n",
      "MINK4575      5822 non-null int64\n",
      "MINK7512      5822 non-null int64\n",
      "MINK123M      5822 non-null int64\n",
      "MINKGEM       5822 non-null int64\n",
      "MKOOPKLA      5822 non-null int64\n",
      "PWAPART       5822 non-null int64\n",
      "PWABEDR       5822 non-null int64\n",
      "PWALAND       5822 non-null int64\n",
      "PPERSAUT      5822 non-null int64\n",
      "PBESAUT       5822 non-null int64\n",
      "PMOTSCO       5822 non-null int64\n",
      "PVRAAUT       5822 non-null int64\n",
      "PAANHANG      5822 non-null int64\n",
      "PTRACTOR      5822 non-null int64\n",
      "PWERKT        5822 non-null int64\n",
      "PBROM         5822 non-null int64\n",
      "PLEVEN        5822 non-null int64\n",
      "PPERSONG      5822 non-null int64\n",
      "PGEZONG       5822 non-null int64\n",
      "PWAOREG       5822 non-null int64\n",
      "PBRAND        5822 non-null int64\n",
      "PZEILPL       5822 non-null int64\n",
      "PPLEZIER      5822 non-null int64\n",
      "PFIETS        5822 non-null int64\n",
      "PINBOED       5822 non-null int64\n",
      "PBYSTAND      5822 non-null int64\n",
      "AWAPART       5822 non-null int64\n",
      "AWABEDR       5822 non-null int64\n",
      "AWALAND       5822 non-null int64\n",
      "APERSAUT      5822 non-null int64\n",
      "ABESAUT       5822 non-null int64\n",
      "AMOTSCO       5822 non-null int64\n",
      "AVRAAUT       5822 non-null int64\n",
      "AAANHANG      5822 non-null int64\n",
      "ATRACTOR      5822 non-null int64\n",
      "AWERKT        5822 non-null int64\n",
      "ABROM         5822 non-null int64\n",
      "ALEVEN        5822 non-null int64\n",
      "APERSONG      5822 non-null int64\n",
      "AGEZONG       5822 non-null int64\n",
      "AWAOREG       5822 non-null int64\n",
      "ABRAND        5822 non-null int64\n",
      "AZEILPL       5822 non-null int64\n",
      "APLEZIER      5822 non-null int64\n",
      "AFIETS        5822 non-null int64\n",
      "AINBOED       5822 non-null int64\n",
      "ABYSTAND      5822 non-null int64\n",
      "Purchase      5822 non-null object\n",
      "dtypes: int64(86), object(1)\n",
      "memory usage: 3.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Info\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0      MOSTYPE     MAANTHUI      MGEMOMV     MGEMLEEF  \\\n",
      "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
      "mean   2911.500000    24.253349     1.110615     2.678805     2.991240   \n",
      "std    1680.810965    12.846706     0.405842     0.789835     0.814589   \n",
      "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "25%    1456.250000    10.000000     1.000000     2.000000     2.000000   \n",
      "50%    2911.500000    30.000000     1.000000     3.000000     3.000000   \n",
      "75%    4366.750000    35.000000     1.000000     3.000000     3.000000   \n",
      "max    5822.000000    41.000000    10.000000     5.000000     6.000000   \n",
      "\n",
      "          MOSHOOFD       MGODRK       MGODPR       MGODOV       MGODGE  \\\n",
      "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
      "mean      5.773617     0.696496     4.626932     1.069907     3.258502   \n",
      "std       2.856760     1.003234     1.715843     1.017503     1.597647   \n",
      "min       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       3.000000     0.000000     4.000000     0.000000     2.000000   \n",
      "50%       7.000000     0.000000     5.000000     1.000000     3.000000   \n",
      "75%       8.000000     1.000000     6.000000     2.000000     4.000000   \n",
      "max      10.000000     9.000000     9.000000     5.000000     9.000000   \n",
      "\n",
      "          ...            ALEVEN     APERSONG      AGEZONG      AWAOREG  \\\n",
      "count     ...       5822.000000  5822.000000  5822.000000  5822.000000   \n",
      "mean      ...          0.076606     0.005325     0.006527     0.004638   \n",
      "std       ...          0.377569     0.072782     0.080532     0.077403   \n",
      "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
      "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
      "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
      "75%       ...          0.000000     0.000000     0.000000     0.000000   \n",
      "max       ...          8.000000     1.000000     1.000000     2.000000   \n",
      "\n",
      "            ABRAND      AZEILPL     APLEZIER       AFIETS      AINBOED  \\\n",
      "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
      "mean      0.570079     0.000515     0.006012     0.031776     0.007901   \n",
      "std       0.562058     0.022696     0.081632     0.210986     0.090463   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       7.000000     1.000000     2.000000     3.000000     2.000000   \n",
      "\n",
      "          ABYSTAND  \n",
      "count  5822.000000  \n",
      "mean      0.014256  \n",
      "std       0.119996  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       0.000000  \n",
      "75%       0.000000  \n",
      "max       2.000000  \n",
      "\n",
      "[8 rows x 86 columns]\n"
     ]
    }
   ],
   "source": [
    "# Describe\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No     5474\n",
      "Yes     348\n",
      "Name: Purchase, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Purchase\n",
    "print(df['Purchase'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, 384 out of 5474 customers purchased insurance. Because of the large spread of each feature, it is necessary to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[df.columns.difference(['Purchase'])])\n",
    "df_norm = scaler.transform(df[df.columns.difference(['Purchase'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165.0378473951887\n",
      "0.16470778193193808\n",
      "1.0000000000000002\n",
      "0.9999999999999997\n"
     ]
    }
   ],
   "source": [
    "# Verify result of standardization\n",
    "print(df.iloc[:,1].var())\n",
    "print(df.iloc[:,2].var())\n",
    "print(df_norm[:,1].var())\n",
    "print(df_norm[:,2].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the data into a test set, containing the first 1,000 observations, and a training set, containing the remaining observations. We fit a KNN model on the training data using K=1, and evaluate the performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5822, 86)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 87)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:1000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 86) (1000,) (4822, 86) (4822,)\n"
     ]
    }
   ],
   "source": [
    "# Create training and test sets\n",
    "X_train = df_norm[0:1000,0:86] \n",
    "y_train = (df.iloc[0:1000,-1] == \"Yes\")\n",
    "X_test = df_norm[1000:,0:86] \n",
    "y_test = (df.iloc[1000:,-1] == \"Yes\")\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, fit model, and make predictions\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "y_pred = knn.fit(X_train,y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.889879717959353\n"
     ]
    }
   ],
   "source": [
    "# Pring accuracy\n",
    "print(\"Accuracy = \", np.mean(y_test == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([False,  True]), array([4502,  320]))\n"
     ]
    }
   ],
   "source": [
    "# Print categorization summary\n",
    "print(np.unique(y_pred, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the accuracy seems good, a random guess will be correct 94% of the time since the \"False\" category stands for 94% of the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, fit model, and make predictions\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "y_pred = knn.fit(X_train,y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9251347988386561\n"
     ]
    }
   ],
   "source": [
    "# Pring accuracy\n",
    "print(\"Accuracy = \", np.mean(y_test == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([False,  True]), array([4696,  126]))\n"
     ]
    }
   ],
   "source": [
    "# Print categorization summary\n",
    "print(np.unique(y_pred, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026831345826235094\n"
     ]
    }
   ],
   "source": [
    "print(126/4696)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4434  262]\n",
      " [  99   27]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.94      0.98      0.96      4533\n",
      "       True       0.21      0.09      0.13       289\n",
      "\n",
      "avg / total       0.90      0.93      0.91      4822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
